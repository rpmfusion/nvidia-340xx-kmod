diff -Naur a/kernel/nv-mmap.c b/kernel/nv-mmap.c
--- a/kernel/nv-mmap.c	2019-12-11 23:04:24.000000000 +0100
+++ b/kernel/nv-mmap.c	2023-05-08 18:24:23.402897733 +0200
@@ -312,7 +312,11 @@
             goto done;
         }

+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 3, 0)
+        vm_flags_set(vma, VM_IO);
+#else
         vma->vm_flags |= VM_IO;
+#endif
     }
     else
     {
@@ -363,8 +367,13 @@

         NV_PRINT_AT(NV_DBG_MEMINFO, at);

+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 3, 0)
+        vm_flags_set(vma, VM_IO | VM_LOCKED | VM_RESERVED);
+        vm_flags_set(vma, VM_DONTEXPAND | VM_DONTDUMP);
+#else
         vma->vm_flags |= (VM_IO | VM_LOCKED | VM_RESERVED);
         vma->vm_flags |= (VM_DONTEXPAND | VM_DONTDUMP);
+#endif
     }

     if (status == 0)
@@ -374,8 +383,13 @@
         if ((prot & NV_PROTECT_WRITEABLE) == 0)
         {
             vma->vm_page_prot = NV_PGPROT_READ_ONLY(vma->vm_page_prot);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 3, 0)
+            vm_flags_clear(vma, VM_WRITE);
+            vm_flags_clear(vma, VM_MAYWRITE);
+#else
             vma->vm_flags &= ~VM_WRITE;
             vma->vm_flags &= ~VM_MAYWRITE;
+#endif
         }

         vma->vm_ops = &nv_vm_ops;
diff -Naur a/kernel/uvm/nvidia_uvm_lite.c b/kernel/uvm/nvidia_uvm_lite.c
--- a/kernel/uvm/nvidia_uvm_lite.c	2023-03-04 13:09:34.850313572 +0100
+++ b/kernel/uvm/nvidia_uvm_lite.c	2023-05-08 18:26:25.391148890 +0200
@@ -1524,10 +1524,17 @@

         vma->vm_ops   = &uvmlite_vma_ops;

+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 3, 0)
+        // Prohibit copying the vma on fork().
+        vm_flags_set(vma, VM_DONTCOPY);
+        // Prohibt mremap() that would expand the vma.
+        vm_flags_set(vma, VM_DONTEXPAND);
+#else
         // Prohibit copying the vma on fork().
         vma->vm_flags |= VM_DONTCOPY;
         // Prohibt mremap() that would expand the vma.
         vma->vm_flags |= VM_DONTEXPAND;
+#endif

         // Other cases of vma modification are detected in _mmap_open().

@@ -1546,9 +1553,15 @@
             return -EINVAL;

         vma->vm_ops = &counters_vma_ops;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 3, 0)
+        vm_flags_clear(vma, VM_MAYWRITE);
+        // prevent vm_insert_page from modifying the vma's flags:
+        vm_flags_set(vma, VM_MIXEDMAP);
+#else
         vma->vm_flags &= ~VM_MAYWRITE;
         // prevent vm_insert_page from modifying the vma's flags:
         vma->vm_flags |= VM_MIXEDMAP;
+#endif
         ret = 0;
     }
     UVM_DBG_PRINT_RL("vma 0x%p [0x%p, 0x%p) ret %d pgoff"
@@ -2527,8 +2540,13 @@
     // Subsequent access from userspace after the pages are unmapped will cause
     // a SIGSEGV.
     //
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 3, 0)
+    vm_flags_clear(vma, VM_READ|VM_MAYREAD);
+    vm_flags_clear(vma, VM_WRITE|VM_MAYWRITE);
+#else
     vma->vm_flags &= ~(VM_READ|VM_MAYREAD);
     vma->vm_flags &= ~(VM_WRITE|VM_MAYWRITE);
+#endif
 }

 //
@@ -2536,8 +2554,13 @@
 //
 static void _set_vma_accessible(struct vm_area_struct * vma)
 {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 3, 0)
+    vm_flags_set(vma, VM_READ|VM_MAYREAD);
+    vm_flags_set(vma, VM_WRITE|VM_MAYWRITE);
+#else
     vma->vm_flags |= (VM_READ|VM_MAYREAD);
     vma->vm_flags |= (VM_WRITE|VM_MAYWRITE);
+#endif
 }

 //
